import streamlit as st
import yfinance as yf
import feedparser
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
from transformers import pipeline
from sklearn.linear_model import LinearRegression
import urllib.parse
import numpy as np

# --- 0. ã‚°ãƒ©ãƒ•è¡¨ç¤ºã®å®‰å®šåŒ–è¨­å®š ---
import matplotlib
matplotlib.use('Agg')

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIæŠ•è³‡è¨ºæ–­(åˆå¿ƒè€…ã‚¬ã‚¤ãƒ‰ä»˜)", layout="wide")
st.title("ğŸŒ AIéŠ˜æŸ„è¨ºæ–­ï¼šä¸–ç•Œãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼†é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰")

# --- 2. AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_ai():
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

analyzer = load_ai()

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("è¨ºæ–­è¨­å®š")
stocks = {
    "ãƒ†ã‚¹ãƒ©": "TSLA", "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢": "PLTR", "ãƒˆãƒ¨ã‚¿": "7203.T",
    "ä»»å¤©å ‚": "7974.T", "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢": "NVDA", "Apple": "AAPL",
    "ã‚½ãƒ‹ãƒ¼": "6758.T", "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G": "9984.T"
}
selected_names = st.sidebar.multiselect("åˆ†æã™ã‚‹éŠ˜æŸ„ã‚’é¸æŠ", list(stocks.keys()), default=["ãƒ†ã‚¹ãƒ©", "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢", "ãƒˆãƒ¨ã‚¿"])
time_span = st.sidebar.radio("è¡¨ç¤ºã‚¹ãƒ‘ãƒ³ï¼ˆæœŸé–“ï¼‰", ["1é€±é–“", "30æ—¥", "1å¹´", "5å¹´", "10å¹´"], index=1)
span_map = {"1é€±é–“": "7d", "30æ—¥": "1mo", "1å¹´": "1y", "5å¹´": "5y", "10å¹´": "10y"}

# --- â˜…åˆå¿ƒè€…å‘ã‘ï¼šãƒ‹ãƒ¥ãƒ¼ã‚¹è©•ä¾¡ã®è§£èª¬ãƒ‘ãƒãƒ« ---
with st.expander("ğŸ’¡ ãƒ‹ãƒ¥ãƒ¼ã‚¹è©•ä¾¡ã®ä»•çµ„ã¿ï¼ˆåˆã‚ã¦ã®æ–¹ã¸ï¼‰"):
    st.write("""
    ã“ã®ã‚¢ãƒ—ãƒªã®AIã¯ã€ä¸–ç•Œä¸­ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¦‹å‡ºã—ã‚’èª­ã‚“ã§ã€ãã®å†…å®¹ãŒ**ã€ŒãŠç¥ã„ãƒ ãƒ¼ãƒ‰ï¼ˆæ ªãŒä¸ŠãŒã‚Šãã†ï¼‰ã€**ã‹**ã€Œæ‚²è¦³ãƒ ãƒ¼ãƒ‰ï¼ˆä¸‹ãŒã‚Šãã†ï¼‰ã€**ã‹ã‚’åˆ¤å®šã—ã¦ã„ã¾ã™ã€‚
    * **â˜…5.0 (çµ¶å¥½èª¿)**ï¼šæ˜ã‚‹ã„ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒå¤šãã€æœŸå¾…ãŒé«˜ã¾ã£ã¦ã„ã¾ã™ã€‚
    * **â˜…3.0 (æ™®é€š)**ï¼šç‰¹ã«å¤§ããªãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒãªã„ã‹ã€è‰¯ã„æ‚ªã„ãŒåŠã€…ã®çŠ¶æ…‹ã§ã™ã€‚
    * **â˜…1.0 (æ³¨æ„)**ï¼šãƒˆãƒ©ãƒ–ãƒ«ã‚„æ¥­ç¸¾ä¸æŒ¯ãªã©ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒç›®ç«‹ã£ã¦ã„ã¾ã™ã€‚
    
    â€»æ—¥æœ¬æ ªã¯æ—¥æœ¬ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ç±³å›½æ ªã¯æœ¬å ´ç±³å›½ã®è‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ç›´æ¥AIãŒèª­ã¿è§£ã„ã¦ã„ã¾ã™ï¼
    """)

# --- 4. å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
if st.sidebar.button("åˆ†æã‚’å®Ÿè¡Œ"):
    results = []
    plot_data = {} 
    
    with st.spinner('AIãŒæœ€æ–°æƒ…å ±ã‚’åˆ†æä¸­...'):
        for name in selected_names:
            try:
                symbol = stocks[name]
                df = yf.download(symbol, period=span_map[time_span], progress=False)
                if len(df) < 2: continue
                plot_data[name] = df

                # äºˆæ¸¬è¨ˆç®—
                y = df['Close'].tail(30).values.reshape(-1, 1)
                X = np.arange(len(y)).reshape(-1, 1)
                model = LinearRegression(); model.fit(X, y)
                pred_price = model.predict([[len(y)]])[0][0]
                last_price = float(df['Close'].iloc[-1])
                diff_pct = ((pred_price - last_price) / last_price) * 100
                
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
                is_japan = symbol.endswith(".T")
                if is_japan:
                    query = urllib.parse.quote(name)
                    url = f"https://news.google.com/rss/search?q={query}&hl=ja&gl=JP&ceid=JP:ja"
                else:
                    query = urllib.parse.quote(symbol.split('.')[0])
                    url = f"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en"
                
                feed = feedparser.parse(url)
                stars, count, top_news = 0, 0, "ãªã—"
                if feed.entries:
                    top_news = feed.entries[0].title
                    for entry in feed.entries[:3]:
                        res = analyzer(entry.title)[0]
                        stars += int(res['label'].split()[0])
                        count += 1
                avg_stars = stars / count if count > 0 else 3
                
                # â˜…AIåˆ¤å®šã«åŸºã¥ã„ãŸæ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆ
                status = "ğŸ˜Š æœŸå¾…" if avg_stars > 3.5 else "ğŸ˜ ä¸­ç«‹" if avg_stars >= 2.5 else "âš ï¸ æ³¨æ„"
                
                results.append({
                    "éŠ˜æŸ„": name, "ç¾åœ¨ä¾¡æ ¼": round(last_price, 2),
                    "AIäºˆæ¸¬(æ˜æ—¥)": round(float(pred_price), 2),
                    "AIåˆ¤å®š": status,
                    "è©•ä¾¡è©³ç´°": f"{avg_stars:.1f} â˜…",
                    "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„": top_news[:40] + "...",
                    "score": float(diff_pct) + (avg_stars - 3)
                })
            except: continue

    if results:
        res_df =
