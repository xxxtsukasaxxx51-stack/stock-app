import streamlit as st
import yfinance as yf
import feedparser
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
from transformers import pipeline
from sklearn.linear_model import LinearRegression
import urllib.parse
import numpy as np

# --- 0. ã‚°ãƒ©ãƒ•è¡¨ç¤ºã®å®‰å®šåŒ–è¨­å®š (ã“ã‚Œã‚’è¿½åŠ ) ---
import matplotlib
matplotlib.use('Agg')

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIæŠ•è³‡è¨ºæ–­ã‚¢ãƒ—ãƒª", layout="wide")
st.title("ğŸš€ AIéŠ˜æŸ„è¨ºæ–­ãƒ©ãƒ³ã‚­ãƒ³ã‚°")

# --- 2. AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_ai():
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

analyzer = load_ai()

# --- 3. éŠ˜æŸ„è¨­å®š ---
stocks = {
    "ãƒ†ã‚¹ãƒ©": "TSLA",
    "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢": "PLTR",
    "ãƒˆãƒ¨ã‚¿": "7203.T",
    "ä»»å¤©å ‚": "7974.T",
    "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢": "NVDA",
    "Apple": "AAPL"
}
selected_names = st.sidebar.multiselect("åˆ†æã™ã‚‹éŠ˜æŸ„ã‚’é¸æŠ", list(stocks.keys()), default=["ãƒ†ã‚¹ãƒ©", "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢", "ãƒˆãƒ¨ã‚¿"])

# --- 4. å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
if st.sidebar.button("åˆ†æã‚’å®Ÿè¡Œ"):
    results = []
    plot_data = {} # ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹å ´æ‰€
    
    with st.spinner('AIãŒåˆ†æä¸­...'):
        for name in selected_names:
            try:
                symbol = stocks[name]
                df = yf.download(symbol, period="3mo", progress=False)
                if len(df) < 10: continue
                
                # ã‚°ãƒ©ãƒ•ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
                plot_data[name] = df.tail(30)

                # äºˆæ¸¬è¨ˆç®—
                y = df.tail(30)['Close'].values.reshape(-1, 1)
                X = np.arange(len(y)).reshape(-1, 1)
                
                model = LinearRegression()
                model.fit(X, y)
                pred_price = model.predict([[len(y)]])[0][0]
                
                last_price = float(y[-1][0])
                diff_pct = ((pred_price - last_price) / last_price) * 100
                
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æ
                query = urllib.parse.quote(name)
                url = f"https://news.google.com/rss/search?q={query}&hl=ja&gl=JP&ceid=JP:ja"
                feed = feedparser.parse(url)
                
                stars, count = 0, 0
                for entry in feed.entries[:2]:
                    res = analyzer(entry.title)[0]
                    stars += int(res['label'].split()[0])
                    count += 1
                avg_stars = stars / count if count > 0 else 3
                
                results.append({
                    "éŠ˜æŸ„": name,
                    "ç¾åœ¨ä¾¡æ ¼": round(last_price, 2),
                    "AIäºˆæ¸¬(æ˜æ—¥)": round(float(pred_price), 2),
                    "æœŸå¾…å€¤(%)": round(float(diff_pct), 2),
                    "ãƒ‹ãƒ¥ãƒ¼ã‚¹è©•ä¾¡": f"{avg_stars:.1f} â˜…",
                    "score": float(diff_pct) + (avg_stars - 3)
                })
            except Exception as e:
                continue

    if results:
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
        res_df = pd.DataFrame(results).sort_values(by="score", ascending=False)
        res_df.insert(0, "é †ä½", range(1, len(res_df) + 1))
        st.subheader("ğŸ† æ³¨ç›®éŠ˜æŸ„ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        st.table(res_df.drop(columns="score"))

        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        st.subheader("ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰æ¯”è¼ƒ (ç›´è¿‘30æ—¥)")
        fig, ax = plt.subplots(figsize=(10, 4))
        for name, data in plot_data.items():
            norm_price = data['Close'] / data['Close'].iloc[0] * 100
            ax.plot(data.index, norm_price, label=name)
        plt.axhline(100, color='black', linestyle='--', alpha=0.3)
        plt.legend()
        st.pyplot(fig)
    else:
        st.error("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§éŠ˜æŸ„ã‚’é¸ã³ç›´ã—ã¦ãã ã•ã„ã€‚")

st.info("ğŸ’¡ AIäºˆæ¸¬ã¯çµ±è¨ˆçš„ãªãƒˆãƒ¬ãƒ³ãƒ‰ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚")
