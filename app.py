import streamlit as st
import yfinance as yf
import feedparser
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
from transformers import pipeline
from sklearn.linear_model import LinearRegression
import urllib.parse
import numpy as np

# --- 0. ã‚°ãƒ©ãƒ•è¡¨ç¤ºã®å®‰å®šåŒ–è¨­å®š ---
import matplotlib
matplotlib.use('Agg')

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIãƒãƒ¼ã‚±ãƒƒãƒˆç·åˆè¨ºæ–­", layout="wide")

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
    <style>
    .main { background-color: #f0f2f6; }
    .market-box { background-color: #1e1e1e; color: #ffffff; padding: 15px; border-radius: 10px; margin-bottom: 20px; }
    .stMetric { background-color: #ffffff; padding: 15px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    </style>
    """, unsafe_allow_html=True)

# --- 2. å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆç‚ºæ›¿ãƒ»å¸‚å ´æŒ‡æ•°ï¼‰ ---
@st.cache_data(ttl=300) # 5åˆ†ã”ã¨ã«æ›´æ–°
def get_market_indices():
    indices = {
        "ãƒ‰ãƒ«å††": "JPY=X",
        "æ—¥çµŒå¹³å‡": "^N225",
        "NYãƒ€ã‚¦": "^DJI"
    }
    data = {}
    for name, ticker in indices.items():
        try:
            info = yf.download(ticker, period="2d", progress=False)
            current = info['Close'].iloc[-1]
            prev = info['Close'].iloc[-2]
            diff = current - prev
            data[name] = (current, diff)
        except:
            data[name] = (0, 0)
    return data

indices_data = get_market_indices()

# --- 3. ç”»é¢è¡¨ç¤º ---
st.title("ğŸŒ AIãƒãƒ¼ã‚±ãƒƒãƒˆç·åˆè¨ºæ–­ï¼šä¸–ç•Œæƒ…å‹¢ Ã— æœªæ¥äºˆæ¸¬")

# â˜…ãƒãƒ¼ã‚±ãƒƒãƒˆæƒ…å ±ã®è¡¨ç¤º
st.markdown("### ğŸ“Š ä¸»è¦ãƒãƒ¼ã‚±ãƒƒãƒˆæŒ‡æ¨™")
m_col1, m_col2, m_col3 = st.columns(3)
with m_col1:
    st.metric("ğŸ’´ ãƒ‰ãƒ«å††", f"{indices_data['ãƒ‰ãƒ«å††'][0]:.2f}å††", f"{indices_data['ãƒ‰ãƒ«å††'][1]:+.2f}")
with m_col2:
    st.metric("ğŸ‡¯ğŸ‡µ æ—¥çµŒå¹³å‡", f"{indices_data['æ—¥çµŒå¹³å‡'][0]:,.0f}å††", f"{indices_data['æ—¥çµŒå¹³å‡'][1]:+,.0f}")
with m_col3:
    st.metric("ğŸ‡ºğŸ‡¸ NYãƒ€ã‚¦", f"{indices_data['NYãƒ€ã‚¦'][0]:,.0f}ãƒ‰ãƒ«", f"{indices_data['NYãƒ€ã‚¦'][1]:+,.0f}")

st.markdown("---")

# --- 4. AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_ai():
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

analyzer = load_ai()

# --- 5. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("ğŸ’° æœªæ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    future_investment = st.number_input("ã„ã¾ã€ã„ãã‚‰æŠ•è³‡ã™ã‚‹ï¼Ÿ(å††)", min_value=1000, value=100000, step=10000)
    
    st.header("âš™ï¸ åˆ†æéŠ˜æŸ„")
    stocks = {
        "ãƒ†ã‚¹ãƒ©": "TSLA", "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢": "PLTR", "ãƒˆãƒ¨ã‚¿": "7203.T",
        "ä»»å¤©å ‚": "7974.T", "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢": "NVDA", "Apple": "AAPL",
        "ã‚½ãƒ‹ãƒ¼": "6758.T", "ä¸‰è±UFJ": "8306.T", "æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³": "8035.T"
    }
    selected_names = st.multiselect("éŠ˜æŸ„ã‚’é¸æŠ", list(stocks.keys()), default=["ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢", "ãƒˆãƒ¨ã‚¿"])
    execute = st.button("ğŸš€ ä¸–ç•Œæƒ…å‹¢ã¨æœªæ¥ã‚’è¨ºæ–­")

# --- 6. å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯ ---
if execute:
    results = []
    
    with st.spinner('ä¸–ç•Œä¸­ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸä¸­...'):
        for name in selected_names:
            try:
                symbol = stocks[name]
                df = yf.download(symbol, period="1mo", progress=False)
                current_price = float(df['Close'].iloc[-1])
                
                # AIäºˆæ¸¬ï¼ˆç·šå½¢å›å¸°ï¼‰
                y_data = df['Close'].tail(20).values.reshape(-1, 1)
                X_data = np.arange(len(y_data)).reshape(-1, 1)
                model = LinearRegression(); model.fit(X_data, y_data)
                predicted_price = model.predict([[len(y_data)]])[0][0]
                change_rate = (predicted_price / current_price)
                
                future_value = future_investment * change_rate
                profit_loss = future_value - future_investment
                
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨ä¸–ç•Œæƒ…å‹¢ã®è§£æ
                is_japan = symbol.endswith(".T")
                query = name if is_japan else symbol.split('.')[0]
                lang = "ja" if is_japan else "en"
                url = f"https://news.google.com/rss/search?q={urllib.parse.quote(query)}&hl={lang}&gl={'JP' if is_japan else 'US'}"
                feed = feedparser.parse(url)
                
                stars = 3
                topic = "é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã—"
                if feed.entries:
                    topic = feed.entries[0].title
                    stars = sum([int(analyzer(e.title)[0]['label'].split()[0]) for e in feed.entries[:3]]) / 3
                
                results.append({
                    "éŠ˜æŸ„": name,
                    "ä¾¡æ ¼": f"{current_price:,.1f}" + ("å††" if is_japan else "ãƒ‰ãƒ«"),
                    "æ˜æ—¥ã¸ã®äºˆæ¸¬": f"{future_value:,.0f}å††",
                    "æç›Šäºˆæƒ³": f"{profit_loss:+,.0f}å††",
                    "æƒ…å‹¢è©•ä¾¡": f"{stars:.1f}â˜…",
                    "æ³¨ç›®ãƒˆãƒ”ãƒƒã‚¯": topic[:45] + "..."
                })
            except: continue

    if results:
        st.subheader("ğŸ† å€‹åˆ¥éŠ˜æŸ„ã®æœªæ¥è¨ºæ–­")
        # ãƒªãƒƒãƒãªçµæœè¡¨ç¤º
        for res in results:
            with st.expander(f"ğŸ“Œ {res['éŠ˜æŸ„']} ã®è©³ç´°è¨ºæ–­çµæœ", expanded=True):
                c1, c2, c3 = st.columns([1, 1, 2])
                c1.metric("äºˆæ¸¬è³‡ç”£é¡", res['äºˆæ¸¬é¡' if 'äºˆæ¸¬é¡' in res else 'æ˜æ—¥ã¸ã®äºˆæ¸¬'], res['æç›Šäºˆæƒ³'])
                c2.metric("AIæƒ…å‹¢ã‚¹ã‚³ã‚¢", res['æƒ…å‹¢è©•ä¾¡'])
                c3.write(f"**æœ€æ–°ã®ä¸–ç•Œæƒ…å‹¢ãƒˆãƒ”ãƒƒã‚¯:**\n{res['æ³¨ç›®ãƒˆãƒ”ãƒƒã‚¯']}")
                
        st.table(pd.DataFrame(results))
    else:
        st.info("å·¦å´ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰éŠ˜æŸ„ã‚’é¸ã‚“ã§ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

st.caption("â€»ç‚ºæ›¿ãƒ»æŒ‡æ•°ãƒ»ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ãŸç·åˆè¨ºæ–­ã§ã™ã€‚æœ€çµ‚çš„ãªæŠ•è³‡åˆ¤æ–­ã¯ã”è‡ªèº«ã®è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€‚")
