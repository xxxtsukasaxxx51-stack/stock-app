import streamlit as st
import yfinance as yf
import feedparser
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
from transformers import pipeline
from sklearn.linear_model import LinearRegression
import urllib.parse
import numpy as np

# --- 0. ã‚°ãƒ©ãƒ•è¡¨ç¤ºã®å®‰å®šåŒ–è¨­å®š ---
import matplotlib
matplotlib.use('Agg')

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIæŠ•è³‡è¨ºæ–­(ä¸–ç•Œå¯¾å¿œç‰ˆ)", layout="wide")
st.title("ğŸŒ AIéŠ˜æŸ„è¨ºæ–­ï¼šä¸–ç•Œãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼†é•·æœŸãƒˆãƒ¬ãƒ³ãƒ‰")

# --- 2. AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ (å¤šè¨€èªå¯¾å¿œ) ---
@st.cache_resource
def load_ai():
    # è‹±èªãƒ»æ—¥æœ¬èªã‚’å«ã‚€å¤šè¨€èªã‚’åŒæ™‚ã«ç†è§£ã§ãã‚‹å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã§ã™
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

analyzer = load_ai()

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("è¨ºæ–­è¨­å®š")
stocks = {
    "ãƒ†ã‚¹ãƒ©": "TSLA", "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢": "PLTR", "ãƒˆãƒ¨ã‚¿": "7203.T",
    "ä»»å¤©å ‚": "7974.T", "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢": "NVDA", "Apple": "AAPL",
    "ã‚½ãƒ‹ãƒ¼": "6758.T", "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G": "9984.T"
}
selected_names = st.sidebar.multiselect("åˆ†æã™ã‚‹éŠ˜æŸ„", list(stocks.keys()), default=["ãƒ†ã‚¹ãƒ©", "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢", "ãƒˆãƒ¨ã‚¿"])
time_span = st.sidebar.radio("è¡¨ç¤ºã‚¹ãƒ‘ãƒ³", ["1å¹´", "5å¹´", "10å¹´"])
span_map = {"1å¹´": "1y", "5å¹´": "5y", "10å¹´": "10y"}

# --- 4. å®Ÿè¡Œãƒœã‚¿ãƒ³ ---
if st.sidebar.button("åˆ†æã‚’å®Ÿè¡Œ"):
    results = []
    plot_data = {} 
    
    with st.spinner('ä¸–ç•Œä¸­ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨æ ªä¾¡ã‚’åé›†ä¸­...'):
        for name in selected_names:
            try:
                symbol = stocks[name]
                df = yf.download(symbol, period=span_map[time_span], progress=False)
                if len(df) < 20: continue
                plot_data[name] = df

                # AIäºˆæ¸¬è¨ˆç®—
                y = df['Close'].tail(30).values.reshape(-1, 1)
                X = np.arange(len(y)).reshape(-1, 1)
                model = LinearRegression(); model.fit(X, y)
                pred_price = model.predict([[len(y)]])[0][0]
                last_price = float(y[-1][0])
                diff_pct = ((pred_price - last_price) / last_price) * 100
                
                # --- ã€æ–°æ©Ÿèƒ½ã€‘æ—¥æœ¬ã¨ä¸–ç•Œã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ä½¿ã„åˆ†ã‘ ---
                is_japan = symbol.endswith(".T")
                if is_japan:
                    # æ—¥æœ¬æ ªï¼šæ—¥æœ¬ã®Googleãƒ‹ãƒ¥ãƒ¼ã‚¹(æ—¥æœ¬èª)
                    query = urllib.parse.quote(name)
                    url = f"https://news.google.com/rss/search?q={query}&hl=ja&gl=JP&ceid=JP:ja"
                else:
                    # ç±³å›½æ ªï¼šç±³å›½ã®Googleãƒ‹ãƒ¥ãƒ¼ã‚¹(è‹±èª)
                    query = urllib.parse.quote(symbol.split('.')[0])
                    url = f"https://news.google.com/rss/search?q={query}&hl=en-US&gl=US&ceid=US:en"
                
                feed = feedparser.parse(url)
                stars, count = 0, 0
                top_news = "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"
                
                if feed.entries:
                    top_news = feed.entries[0].title # æœ€æ–°ã®1ä»¶ã‚’ä¿æŒ
                    for entry in feed.entries[:3]: # ç›´è¿‘3ä»¶ã‚’åˆ†æ
                        res = analyzer(entry.title)[0]
                        stars += int(res['label'].split()[0])
                        count += 1
                avg_stars = stars / count if count > 0 else 3
                
                results.append({
                    "éŠ˜æŸ„": name, "ç¾åœ¨ä¾¡æ ¼": round(last_price, 2),
                    "AIäºˆæ¸¬(æ˜æ—¥)": round(float(pred_price), 2),
                    "æœŸå¾…å€¤(%)": round(float(diff_pct), 2),
                    "ãƒ‹ãƒ¥ãƒ¼ã‚¹è©•ä¾¡": f"{avg_stars:.1f} â˜…",
                    "æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹": top_news[:50] + "...", # ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
                    "score": float(diff_pct) + (avg_stars - 3)
                })
            except: continue

    if results:
        # ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
        res_df = pd.DataFrame(results).sort_values(by="score", ascending=False)
        st.subheader(f"ğŸ† AIç·åˆè©•ä¾¡ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã‚’å«ã‚ã¦è¡¨ç¤º
        st.dataframe(res_df.drop(columns="score"), use_container_width=True)

        # ã‚°ãƒ©ãƒ•è¡¨ç¤º
        st.subheader(f"ğŸ“ˆ {time_span}ãƒˆãƒ¬ãƒ³ãƒ‰ ï¼† æ˜æ—¥ã®äºˆæ¸¬(â˜…)")
        fig, ax = plt.subplots(figsize=(12, 6))
        for name, data in plot_data.items():
            norm_price = data['Close'] / data['Close'].iloc[0] * 100
            line = ax.plot(data.index, norm_price, label=name, alpha=0.8)
            
            # äºˆæ¸¬ç‚¹(â˜…)ã®æç”»
            next_date = data.index[-1] + pd.Timedelta(days=1)
            pred_val = [r['AIäºˆæ¸¬(æ˜æ—¥)'] for r in results if r['éŠ˜æŸ„']==name][0]
            norm_pred = (pred_val / data['Close'].iloc[0]) * 100
            ax.scatter(next_date, norm_pred, color=line[0].get_color(), marker='*', s=250, edgecolors='black', zorder=5)
        
        plt.axhline(100, color='black', linestyle='--', alpha=0.3)
        plt.legend()
        st.pyplot(fig)
    else:
        st.error("ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
