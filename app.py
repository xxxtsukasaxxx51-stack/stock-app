import streamlit as st
import yfinance as yf
import feedparser
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
from transformers import pipeline
from sklearn.linear_model import LinearRegression
import urllib.parse
import numpy as np

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š (ã‚¢ãƒ—ãƒªã®è¦‹ãŸç›®) ---
st.set_page_config(page_title="AIæŠ•è³‡è¨ºæ–­ã‚¢ãƒ—ãƒª", layout="wide")

st.title("ğŸš€ AIéŠ˜æŸ„è¨ºæ–­ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
st.markdown("æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æ„Ÿæƒ…åˆ†æã¨çµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹ã€æ˜æ—¥ã¸ã®æŠ•è³‡ã‚¬ã‚¤ãƒ‰ã€‚")

# --- 2. AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ©Ÿèƒ½ã§é«˜é€ŸåŒ–) ---
@st.cache_resource
def load_ai():
    # å¤šè¨€èªå¯¾å¿œã®æ„Ÿæƒ…åˆ†æãƒ¢ãƒ‡ãƒ«
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

analyzer = load_ai()

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("è¨ºæ–­è¨­å®š")
stocks = {
    "ãƒ†ã‚¹ãƒ©": "TSLA",
    "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢": "PLTR",
    "ãƒˆãƒ¨ã‚¿": "7203.T",
    "ä»»å¤©å ‚": "7974.T",
    "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢": "NVDA",
    "Apple": "AAPL"
}
selected_names = st.sidebar.multiselect("åˆ†æã™ã‚‹éŠ˜æŸ„ã‚’é¸æŠ", list(stocks.keys()), default=["ãƒ†ã‚¹ãƒ©", "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢", "ãƒˆãƒ¨ã‚¿"])

# --- 4. è¨ºæ–­ãƒ­ã‚¸ãƒƒã‚¯ ---
if st.sidebar.button("åˆ†æã‚’å®Ÿè¡Œ"):
    results = []
    
    with st.spinner('AIãŒä¸–ç•Œæƒ…å‹¢ã¨æ ªä¾¡ã‚’åˆ†æä¸­...'):
        for name in selected_names:
            symbol = stocks[name]
            
            # æ ªä¾¡å–å¾— & äºˆæ¸¬
            df = yf.download(symbol, period="3mo", progress=False)
            df_study = df.tail(30).copy()
            df_study['Day_Num'] = np.arange(len(df_study))
            
            model = LinearRegression()
            model.fit(df_study[['Day_Num']], df_study['Close'])
            pred_price = model.predict([[len(df_study)]])[0]
            last_price = df['Close'].iloc[-1]
            diff_pct = ((pred_price - last_price) / last_price) * 100
            
            # æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æ
            query = urllib.parse.quote(name)
            url = f"https://news.google.com/rss/search?q={query}&hl=ja&gl=JP&ceid=JP:ja"
            feed = feedparser.parse(url)
            
            stars, count = 0, 0
            for entry in feed.entries[:2]:
                res = analyzer(entry.title)[0]
                stars += int(res['label'].split()[0])
                count += 1
            avg_stars = stars / count if count > 0 else 3
            
            results.append({
                "éŠ˜æŸ„": name,
                "ç¾åœ¨ä¾¡æ ¼": round(last_price, 2),
                "AIäºˆæ¸¬(æ˜æ—¥)": round(pred_price, 2),
                "æœŸå¾…å€¤(%)": round(diff_pct, 2),
                "ãƒ‹ãƒ¥ãƒ¼ã‚¹è©•ä¾¡": f"{avg_stars:.1f} â˜…",
                "score": diff_pct + (avg_stars - 3)
            })

    # --- 5. çµæœè¡¨ç¤º (ãƒ©ãƒ³ã‚­ãƒ³ã‚°) ---
    res_df = pd.DataFrame(results).sort_values(by="score", ascending=False)
    res_df.insert(0, "é †ä½", range(1, len(res_df) + 1))
    
    st.subheader("ğŸ† æ³¨ç›®éŠ˜æŸ„ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    st.table(res_df.drop(columns="score"))

    # --- 6. è¦–è¦šåŒ– ---
    st.subheader("ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰æ¯”è¼ƒ")
    fig, ax = plt.subplots(figsize=(10, 4))
    for name in selected_names:
        df = yf.download(stocks[name], period="1mo", progress=False)
        norm_price = df['Close'] / df['Close'].iloc[0] * 100
        ax.plot(df.index, norm_price, label=name)
    
    plt.axhline(100, color='black', linestyle='--', alpha=0.3)
    plt.legend()
    st.pyplot(fig)
    
    st.info("ğŸ’¡ AIäºˆæ¸¬ã¯çµ±è¨ˆçš„ãªãƒˆãƒ¬ãƒ³ãƒ‰ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»ã§ãŠé¡˜ã„ã—ã¾ã™ã€‚")
else:
    st.write("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰éŠ˜æŸ„ã‚’é¸ã‚“ã§ã€Œåˆ†æã‚’å®Ÿè¡Œã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
