import streamlit as st
import yfinance as yf
import feedparser
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
from transformers import pipeline
from sklearn.linear_model import LinearRegression
import urllib.parse
import numpy as np

# --- 0. ã‚°ãƒ©ãƒ•è¡¨ç¤ºã®å®‰å®šåŒ–è¨­å®š ---
import matplotlib
matplotlib.use('Agg')

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š (ãƒ†ãƒ¼ãƒã‚«ãƒ©ãƒ¼ã‚’æ„è­˜) ---
st.set_page_config(page_title="AIæŠ•è³‡è¨ºæ–­ Premium", layout="wide", initial_sidebar_state="expanded")

# --- ã‚«ã‚¹ã‚¿ãƒ CSSã§ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’æ•´ãˆã‚‹ ---
st.markdown("""
    <style>
    .main { background-color: #f5f7f9; }
    .stButton>button { width: 100%; border-radius: 20px; height: 3em; background-color: #007bff; color: white; border: none; }
    .stMetric { background-color: white; padding: 15px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    </style>
    """, unsafe_allow_html=True)

st.title("ğŸ’ AIéŠ˜æŸ„è¨ºæ–­ Premium")
st.markdown("---")

# --- 2. AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_ai():
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

analyzer = load_ai()

# --- 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    stocks = {
        "ãƒ†ã‚¹ãƒ©": "TSLA", "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢": "PLTR", "ãƒˆãƒ¨ã‚¿": "7203.T",
        "ä»»å¤©å ‚": "7974.T", "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢": "NVDA", "Apple": "AAPL",
        "ã‚½ãƒ‹ãƒ¼": "6758.T", "ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯G": "9984.T"
    }
    selected_names = st.multiselect("åˆ†æéŠ˜æŸ„ã‚’é¸æŠ", list(stocks.keys()), default=["ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢", "ãƒ†ã‚¹ãƒ©"])
    time_span = st.select_slider("è¡¨ç¤ºæœŸé–“", options=["1é€±é–“", "30æ—¥", "1å¹´", "5å¹´", "10å¹´"], value="30æ—¥")
    span_map = {"1é€±é–“": "7d", "30æ—¥": "1mo", "1å¹´": "1y", "5å¹´": "5y", "10å¹´": "10y"}
    
    st.markdown("---")
    execute = st.button("ğŸš€ åˆ†æã‚’é–‹å§‹ã™ã‚‹")

# --- è§£èª¬ãƒ‘ãƒãƒ« ---
with st.expander("â“ ãƒ‹ãƒ¥ãƒ¼ã‚¹è©•ä¾¡ã¨ã¯ï¼Ÿ"):
    st.info("ä¸–ç•Œä¸­ã®æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’AIãŒèª­ã¿å–ã‚Šã€æŠ•è³‡å®¶ã®æ„Ÿæƒ…ã‚’1.0ã€œ5.0ã®æ˜Ÿæ•°ã§æ•°å€¤åŒ–ã—ã¦ã„ã¾ã™ã€‚")

# --- 4. å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯ ---
if execute:
    results = []
    plot_data = {} 
    
    with st.spinner('âœ¨ AIãŒå¸‚å ´ã®æ³¢å‹•ã‚’è§£æä¸­...'):
        for name in selected_names:
            try:
                symbol = stocks[name]
                df = yf.download(symbol, period=span_map[time_span], progress=False)
                if len(df) < 2: continue
                plot_data[name] = df

                # äºˆæ¸¬è¨ˆç®—
                y_data = df['Close'].tail(30).values.reshape(-1, 1)
                X_data = np.arange(len(y_data)).reshape(-1, 1)
                model = LinearRegression(); model.fit(X_data, y_data)
                pred_price = model.predict([[len(y_data)]])[0][0]
                last_price = float(df['Close'].iloc[-1])
                diff_pct = ((pred_price - last_price) / last_price) * 100
                
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—
                is_japan = symbol.endswith(".T")
                if is_japan:
                    url = f"https://news.google.com/rss/search?q={urllib.parse.quote(name)}&hl=ja&gl=JP&ceid=JP:ja"
                else:
                    url = f"https://news.google.com/rss/search?q={urllib.parse.quote(symbol.split('.')[0])}&hl=en-US&gl=US&ceid=US:en"
                
                feed = feedparser.parse(url)
                stars, count, news_title = 0, 0, "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã—"
                if feed.entries:
                    news_title = feed.entries[0].title
                    for entry in feed.entries[:3]:
                        res = analyzer(entry.title)[0]
                        stars += int(res['label'].split()[0])
                        count += 1
                avg_stars = stars / count if count > 0 else 3
                
                results.append({
                    "name": name, "price": last_price, "pred": pred_price, 
                    "diff": diff_pct, "stars": avg_stars, "news": news_title
                })
            except: continue

    if results:
        # --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ1: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º ---
        st.subheader("ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¦ç´„")
        cols = st.columns(len(results))
        for i, res in enumerate(results):
            with cols[i]:
                color = "normal" if res['diff'] >= 0 else "inverse"
                st.metric(label=res['name'], value=f"${res['price']:.2f}", delta=f"{res['diff']:.2f}% (æ˜æ—¥äºˆæ¸¬)", delta_color=color)

        # --- ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ2: ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¨ã‚°ãƒ©ãƒ• ---
        col_table, col_graph = st.columns([1, 1.5])
        
        with col_table:
            st.subheader("ğŸ† ç·åˆè©•ä¾¡")
            res_df = pd.DataFrame(results).sort_values(by="stars", ascending=False)
            st.table(res_df[["name", "stars", "news"]].rename(columns={"name":"éŠ˜æŸ„", "stars":"AIè©•ä¾¡", "news":"æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹"}))

        with col_graph:
            st.subheader("ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬")
            plt.style.use('ggplot') # ãŠã—ã‚ƒã‚Œãªã‚°ãƒ©ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«
            fig, ax = plt.subplots(figsize=(10, 6))
            for name, data in plot_data.items():
                norm_price = data['Close'] / data['Close'].iloc[0] * 100
                line = ax.plot(data.index, norm_price, label=name, linewidth=2)
                
                # äºˆæ¸¬åœ°ç‚¹ã«æ˜Ÿ
                pred_val = [r['pred'] for r in results if r['name']==name][0]
                norm_pred = (pred_val / data['Close'].iloc[0]) * 100
                ax.scatter(data.index[-1] + pd.Timedelta(days=1), norm_pred, color=line[0].get_color(), marker='*', s=300, edgecolors='black', zorder=5)
            
            plt.axhline(100, color='#333333', linestyle='--', alpha=0.2)
            plt.legend()
            st.pyplot(fig)
    else:
        st.error("åˆ†æå¯¾è±¡ã‚’é¸æŠã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
