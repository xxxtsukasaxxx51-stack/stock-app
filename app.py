import streamlit as st
import yfinance as yf
import feedparser
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
from transformers import pipeline
from sklearn.linear_model import LinearRegression
import urllib.parse
import numpy as np

# --- 0. ã‚°ãƒ©ãƒ•è¡¨ç¤ºã®å®‰å®šåŒ–è¨­å®š ---
import matplotlib
matplotlib.use('Agg')

# --- 1. ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AIãƒãƒ¼ã‚±ãƒƒãƒˆç·åˆè¨ºæ–­", layout="wide")

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
    <style>
    .main { background-color: #f0f2f6; }
    .stMetric { background-color: #ffffff; padding: 15px; border-radius: 10px; box-shadow: 0 2px 4px rgba(0,0,0,0.05); }
    </style>
    """, unsafe_allow_html=True)

# --- 2. å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ï¼ˆå®‰å…¨ãªã‚¨ãƒ©ãƒ¼å‡¦ç†ä»˜ãï¼‰ ---
@st.cache_data(ttl=300)
def get_market_indices():
    indices = {
        "ãƒ‰ãƒ«å††": "JPY=X",
        "æ—¥çµŒå¹³å‡": "^N225",
        "NYãƒ€ã‚¦": "^DJI"
    }
    data = {}
    for name, ticker in indices.items():
        try:
            # periodã‚’1moã«ã—ã¦ã€ç›´è¿‘ã®æœ‰åŠ¹ãª2æ—¥é–“ã‚’ç¢ºå®Ÿã«å–å¾—
            info = yf.download(ticker, period="1mo", progress=False)
            if len(info) >= 2:
                current = float(info['Close'].iloc[-1])
                prev = float(info['Close'].iloc[-2])
                diff = current - prev
                data[name] = (current, diff)
            else:
                data[name] = (None, None)
        except:
            data[name] = (None, None)
    return data

indices_data = get_market_indices()

# --- 3. ç”»é¢è¡¨ç¤º ---
st.title("ğŸŒ AIãƒãƒ¼ã‚±ãƒƒãƒˆç·åˆè¨ºæ–­ï¼šä¸–ç•Œæƒ…å‹¢ Ã— æœªæ¥äºˆæ¸¬")

st.markdown("### ğŸ“Š ä¸»è¦ãƒãƒ¼ã‚±ãƒƒãƒˆæŒ‡æ¨™")
m_col1, m_col2, m_col3 = st.columns(3)

# ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã‚’ç¢ºèªã—ãªãŒã‚‰è¡¨ç¤ºï¼ˆã“ã“ã§ã‚¨ãƒ©ãƒ¼ã‚’é˜²æ­¢ï¼‰
def display_metric(col, label, data_tuple, unit=""):
    val, diff = data_tuple
    if val is not None:
        col.metric(label, f"{val:,.2f}{unit}", f"{diff:+,.2f}")
    else:
        col.metric(label, "å–å¾—ä¸­...", "å¸‚å ´ä¼‘æ­¢ä¸­")

display_metric(m_col1, "ğŸ’´ ãƒ‰ãƒ«å††", indices_data['ãƒ‰ãƒ«å††'], "å††")
display_metric(m_col2, "ğŸ‡¯ğŸ‡µ æ—¥çµŒå¹³å‡", indices_data['æ—¥çµŒå¹³å‡'], "å††")
display_metric(m_col3, "ğŸ‡ºğŸ‡¸ NYãƒ€ã‚¦", indices_data['NYãƒ€ã‚¦'], "ãƒ‰ãƒ«")

st.markdown("---")

# --- 4. AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_ai():
    return pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

analyzer = load_ai()

# --- 5. ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("ğŸ’° æœªæ¥ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    future_investment = st.number_input("ã„ã¾ã€ã„ãã‚‰æŠ•è³‡ã™ã‚‹ï¼Ÿ(å††)", min_value=1000, value=100000, step=10000)
    
    st.header("âš™ï¸ åˆ†æéŠ˜æŸ„")
    stocks = {
        "ãƒ†ã‚¹ãƒ©": "TSLA", "ãƒ‘ãƒ©ãƒ³ãƒ†ã‚£ã‚¢": "PLTR", "ãƒˆãƒ¨ã‚¿": "7203.T",
        "ä»»å¤©å ‚": "7974.T", "ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢": "NVDA", "Apple": "AAPL",
        "ã‚½ãƒ‹ãƒ¼": "6758.T", "ä¸‰è±UFJ": "8306.T", "æ±äº¬ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ³": "8035.T"
    }
    selected_names = st.multiselect("éŠ˜æŸ„ã‚’é¸æŠ", list(stocks.keys()), default=["ã‚¨ãƒŒãƒ“ãƒ‡ã‚£ã‚¢", "ãƒˆãƒ¨ã‚¿"])
    execute = st.button("ğŸš€ ä¸–ç•Œæƒ…å‹¢ã¨æœªæ¥ã‚’è¨ºæ–­")

# --- 6. å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯ ---
if execute:
    results = []
    with st.spinner('ä¸–ç•Œä¸­ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¨å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’åŒæœŸä¸­...'):
        for name in selected_names:
            try:
                symbol = stocks[name]
                df = yf.download(symbol, period="1mo", progress=False)
                if len(df) < 5: continue
                
                current_price = float(df['Close'].iloc[-1])
                y_data = df['Close'].tail(20).values.reshape(-1, 1)
                X_data = np.arange(len(y_data)).reshape(-1, 1)
                model = LinearRegression(); model.fit(X_data, y_data)
                predicted_price = float(model.predict([[len(y_data)]])[0][0])
                
                change_rate = predicted_price / current_price
                future_value = future_investment * change_rate
                profit_loss = future_value - future_investment
                
                # ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£æ
                is_japan = symbol.endswith(".T")
                query = name if is_japan else symbol.split('.')[0]
                lang, gl = ("ja", "JP") if is_japan else ("en", "US")
                url = f"https://news.google.com/rss/search?q={urllib.parse.quote(query)}&hl={lang}&gl={gl}"
                feed = feedparser.parse(url)
                
                stars, topic = 3, "é–¢é€£ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã—"
                if feed.entries:
                    topic = feed.entries[0].title
                    stars = sum([int(analyzer(e.title)[0]['label'].split()[0]) for e in feed.entries[:3]]) / 3
                
                results.append({
                    "éŠ˜æŸ„": name,
                    "ä¾¡æ ¼": f"{current_price:,.1f}" + ("å††" if is_japan else "ãƒ‰ãƒ«"),
                    "å°†æ¥ä¾¡å€¤": future_value,
                    "æç›Š": profit_loss,
                    "æƒ…å‹¢è©•ä¾¡": f"{stars:.1f}â˜…",
                    "æœ€æ–°ãƒˆãƒ”ãƒƒã‚¯": topic[:45] + "..."
                })
            except: continue

    if results:
        st.subheader("ğŸ† å€‹åˆ¥éŠ˜æŸ„ã®æœªæ¥è¨ºæ–­")
        for res in results:
            with st.expander(f"ğŸ“Œ {res['éŠ˜æŸ„']} ã®è¨ºæ–­çµæœ", expanded=True):
                c1, c2, c3 = st.columns([1, 1, 2])
                c1.metric("äºˆæ¸¬è³‡ç”£é¡", f"{res['å°†æ¥ä¾¡å€¤']:,.0f}å††", f"{res['æç›Š']:+,.0f}å††")
                c2.metric("AIæƒ…å‹¢ã‚¹ã‚³ã‚¢", res['æƒ…å‹¢è©•ä¾¡'])
                c3.write(f"**æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹:**\n{res['æœ€æ–°ãƒˆãƒ”ãƒƒã‚¯']}")
    else:
        st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰éŠ˜æŸ„ã‚’é¸ã‚“ã§ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")

st.caption("â€»æœ€çµ‚çš„ãªæŠ•è³‡åˆ¤æ–­ã¯ã”è‡ªèº«ã®è²¬ä»»ã§è¡Œã£ã¦ãã ã•ã„ã€‚")
